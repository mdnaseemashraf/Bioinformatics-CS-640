lm.black = lm(crim~black)
lm.lstat = lm(crim~lstat)
lm.medv = lm(crim~medv)
x = c(coefficients(lm.zn)[2], coefficients(lm.indus)[2], coefficients(lm.chas)[2],
coefficients(lm.nox)[2], coefficients(lm.rm)[2], coefficients(lm.age)[2],
coefficients(lm.dis)[2], coefficients(lm.rad)[2], coefficients(lm.tax)[2],
coefficients(lm.ptratio)[2], coefficients(lm.black)[2], coefficients(lm.lstat)[2],
coefficients(lm.medv)[2])
y = coefficients(lm.all)[2:14]
plot(x, y)
lm.zn = lm(crim~poly(zn,3))
summary(lm.zn)
lm.indus = lm(crim~poly(indus,3))
summary(lm.indus)
lm.nox = lm(crim~poly(nox,3))
summary(lm.nox)
lm.rm = lm(crim~poly(rm,3))
summary(lm.rm)
lm.age = lm(crim~poly(age,3))
summary(lm.age)
lm.dis = lm(crim~poly(dis,3))
summary(lm.dis)
lm.rad = lm(crim~poly(rad,3))
summary(lm.rad)
lm.tax = lm(crim~poly(tax,3))
summary(lm.tax)
lm.ptratio = lm(crim~poly(ptratio,3))
summary(lm.ptratio)
lm.black = lm(crim~poly(black,3))
summary(lm.black
lm.black = lm(crim~poly(black,3))
summary(lm.black)
lm.lstat = lm(crim~poly(lstat,3))
summary(lm.lstat)
lm.medv = lm(crim~poly(medv,3))
summary(lm.medv)
require(ISLR)
require(boot)
?cv.glm
plot(mpg~horsepower,data=Auto)
glm.fit=glm(mpg~horsepower, data=Auto)
cv.glm(Auto,glm.fit)$delta #pretty slow (doesnt use formula (5.2) on page 180)
###me entry
cv.glm(Auto,glm.fit)$K
###
##Lets write a simple function to use formula (5.2)
loocv=function(fit){
h=lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
## Now we try it out
loocv(glm.fit)
cv.error=rep(0,5)
degree=1:5
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error[d]=loocv(glm.fit)
}
plot(degree,cv.error,type="b")
## 10-fold CV
cv.error10=rep(0,5)
for(d in degree){
glm.fit=glm(mpg~poly(horsepower,d), data=Auto)
cv.error10[d]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
lines(degree,cv.error10,type="b",col="red")
getwd()
setwd("C:/Users/Naseem Ashraf/Desktop 1/Fall 16/Datamining")
library(ISLR)
library(ISLR)
dim(Hitters)
head(Hitters)
n = dimen[0]
dimen = dim(Hitters)
n = dimen[0]
n
n = dimen[1]
n
d = dimen[2]
head(Hitters)
d
library(ISLR)
dimen = dim(Hitters)
n = dimen[1]
d = dimen[2]
print("n = "+n)
print("n = "+n.toString)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
library(leaps)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
library(ISLR)
library(leaps)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
library(ISLR)
? Hitters
summary(Hitters)
Hitters=na.omit(Hitters)
?na.omit
with(Hitters,sum(is.na(Salary)))
library(leaps)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
Hitters=na.omit(Hitters)
with(Hitters,sum(is.na(Salary)))
with(Hitters,sum(is.na(Salary)))
library(ISLR)
dimen = dim(Hitters)
n = dimen[1]
d = dimen[2]
n
d
Hitters=na.omit(Hitters)
dimen = dim(Hitters)
n = dimen[1]
d = dimen[2]
n
d
library(leaps)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
require(ISLR)
require(tree)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
d1 <- as.dendrogram(tree.carseats)
plot(tree.carseats)
text(d1,pretty=0, pos = 2, srt=90)
text(tree.carseats,pretty=0, pos = 2, srt=90)
plot(d1,type="rectangle", hang= -2)
plot(tree.carseats, hang= -1)
plot(tree.carseats, hang= -10)
text(tree.carseats,pretty=0, pos = 2, srt=90)
plot(tree.carseats, hang= 10)
text(tree.carseats,pretty=0, pos = 2, srt=90)
y <- tree.carseats$y
y <- tree.carseats$y
text(y+1,pretty=0, pos = 2, srt=90)
require(ISLR)
#install.packages('tree', repos="http://cran.r-project.org")
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
plot(tree.carseats);text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+33)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
prune.carseats=prune.misclass(tree.carseats,best=13)
plot(prune.carseats);text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+32)/150
require(ISLR)
require(tree)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+33)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
prune.carseats=prune.misclass(tree.carseats,best=13)
plot(prune.carseats);text(prune.carseats,pretty=0)
prune.carseats
prune.misclass()
prune.misclass(tree.carseats)
getwd()
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
tree.carseats
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
plot(tree.carseats);text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
require(ISLR)
require(tree)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
prune.carseats=prune.misclass(tree.carseats,best=2)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(82+24)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
prune.carseats=prune.misclass(tree.carseats,best=5)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(71+32)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
prune.carseats=prune.misclass(tree.carseats,best=10)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(74+29)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
prune.carseats=prune.misclass(tree.carseats,best=15)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(71+33)/150
setwd("C:/Users/Naseem Ashraf/Desktop 1/Fall 16/Bioinformatics/DESeq2 Assignment")
library('DESeq2')
countTable <- read.table("count_matrix_sub.txt", header=TRUE, sep="\t", row.names=1)
countTable <- read.table("count_matrix_sub.txt", header=TRUE, sep="\t", row.names=1)
ControlCistrackID <- c("2012.562","2012.563","2012.564","2012.565","2012.566","2012.568","2012.569")
E2CistrackID <- c("2012.570","2012.571","2012.572","2012.574","2012.575","2012.576","2012.577" )
numRep <- 7   # 7 repetitions each of untreated, treated
for(readDepth in c("2.5M","10M","30M"))
{
makeDataSet<- function ( data, controlIDs, E2IDs, readDepth){
controlReplicates <- paste( "X", controlIDs, ".subsamp.", sep="")
controlReplicates_readDepth <- paste(controlReplicates, readDepth, sep="")
E2Replicates <- paste( "X", E2IDs, ".subsamp.", sep="")
E2Replicates_readDepth <- paste(E2Replicates, readDepth, sep="")
dataSet <- data[, c(controlReplicates_readDepth, E2Replicates_readDepth)]
return(dataSet)
}
dataset <- makeDataSet(countTable, ControlCistrackID, E2CistrackID, readDepth)
sampleCondition<- c(rep("untreated",numRep), rep("treated",numRep) )
sampleTable<-data.frame(sampleName=colnames(dataset), condition=sampleCondition)
countData = dataset
colData = sampleTable
design = ~ condition
##?DESeqDataSetFromMatrix
deseq2dataset <- DESeqDataSetFromMatrix(countData, colData, design)
##?? deseq2dataset <- DESeqDataSetFromMatrix(countData = dataset, colData = sampleTable, design = ~ condition)
colData(deseq2dataset)
colData(deseq2dataset)$condition<-factor(colData(deseq2dataset)$condition, levels=c("untreated","treated"))
dds<-DESeq(deseq2dataset)     # *** stats for differential expression done here
res<-results(dds)
head(res)
res<-res[order(res$padj),]
head(res)
resSig <- subset(res, res$padj < 0.05 ) # significant fold changes
resSig
genesUp = subset(resSig, resSig$log2FoldChange >=2 )    # up-regulated genes at log2FoldChange >= 2
genesUp <-genesUp[order(genesUp$log2FoldChange),]
genesUp
genesDown = subset(resSig, resSig$log2FoldChange <= -1.5 )  # down-regulated genes at log2FoldChange <= -1.5
genesDown <-genesDown[order(genesDown$log2FoldChange),]
genesDown
#pvalue is the Wald test p-value: condition treated vs untreated
#padj is BH (Benjamini-Hochberg) adjusted p-values <- adjusted to control the false discovery rate
if(readDepth=="2.5M")
{
hist( res$pvalue, breaks=50, col="grey" )
dev.copy(png,"MA-2.5.png")
dev.off()
dev.copy(png,"Hist-padjacent2-2.5.png")
dev.copy(png,"MvA-2.5.png")
dev.off()
}
if(readDepth=="10M")
{
hist( res$pvalue, breaks=50, col="grey" )
dev.copy(png,"Hist-pvalue-10.png")
dev.off()
hist( res$padj, breaks=50, col="grey" )
dev.copy(png,"Hist-padjacent2-10.png")
dev.off()
}
else
{
hist( res$pvalue, breaks=50, col="grey" )
dev.copy(png,"Hist-pvalue-30.png")
dev.off()
hist( res$padj, breaks=50, col="grey" )
dev.copy(png,"Hist-padjacent2-30.png")
dev.off()
}
# MA plot is application of a Bland-Altman plot for visual representation of two channel gene expression data
#  which has been transformed onto the M (log ratios) and A (mean average) scale.
# M vs. A plots of each pair (untreated, treated) is produced.
##plotMA(dds,ylim=c(-2,2),main= paste("DESeq2 ", "2.5M "), alpha=.05 )  # default threshold (ie: alpha) is .1
if(readDepth=="2.5M")
{
plotMA(dds,ylim=c(-2,2),main= paste("DESeq2 ", "2.5M"), alpha=.05 )
dev.copy(png,"MA-2.5.png")
dev.off()
plotMA(dds,ylim=c(-3,3),main= paste("DESeq2 ", "2.5M"), alpha=.05)
dev.copy(png,"MvA-2.5.png")
dev.off()
}
if(readDepth=="10M")
{
plotMA(dds,ylim=c(-2,2),main= paste("DESeq2 ", "10M"), alpha=.05 )
dev.copy(png,"MA-10.png")
dev.off()
plotMA(dds,ylim=c(-3,3),main= paste("DESeq2 ", "10M"), alpha=.05)
dev.copy(png,"MvA-10.png")
dev.off()
}
else
{
plotMA(dds,ylim=c(-2,2),main= paste("DESeq2 ", "30m"), alpha=.05 )
dev.copy(png,"MA-30.png")
dev.off()
plotMA(dds,ylim=c(-3,3),main= paste("DESeq2 ", "30m"), alpha=.05)
dev.copy(png,"MvA-30.png")
dev.off()
}
#transform the raw counts for clustering:
#choose blind so that conditions does not influence the outcome,
# to see if conditions cluster based purely on the individual datasets, in an unbiased way.
rld <- rlogTransformation(dds, blind=TRUE) # regularized log
vsd <- varianceStabilizingTransformation(dds, blind=TRUE) # DESeq's variance stabilisation
################## Biotech may stop here ############################### :) It does not!
#see which approaches have more consistent SD across the read counts
# source("http://bioconductor.org/biocLite.R")
# biocLite("vsn")
library("vsn")
par(mfrow=c(1,3))
notAllZero <- (rowSums(counts(dds))>0)
# log2 doesn't do well for low read counts (SD is high, varies)
#?meanSdPlot
if(readDepth=="2.5M")
{
ylabval = 2.5
meanSdPlot(log2(counts(dds,normalized=TRUE)[notAllZero,] + 1), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_1-2.5.png")
dev.off()
meanSdPlot(assay(rld[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_2-2.5.png")
dev.off()
meanSdPlot(assay(vsd[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_3-2.5.png")
dev.off()
}
if(readDepth=="10M")
{
ylabval = 10
meanSdPlot(log2(counts(dds,normalized=TRUE)[notAllZero,] + 1), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_1-10.png")
dev.off()
meanSdPlot(assay(rld[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_2-10.png")
dev.off()
meanSdPlot(assay(vsd[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_3-10.png")
dev.off()
}
else
{
ylabval = 30
meanSdPlot(log2(counts(dds,normalized=TRUE)[notAllZero,] + 1), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_1-30.png")
dev.off()
meanSdPlot(assay(rld[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_2-30.png")
dev.off()
meanSdPlot(assay(vsd[notAllZero,]), ylab = c(0,ylabval))
dev.copy(png,"deseq2_heatmaps_samplebysample_3-30.png")
dev.off()
}
##n
# regularized log (center) and DESeq's variance stabilisation (right)
#  transformations do better across the  range of counts
# calculate sample to sample Euclidean distances betw lg fold change of genes < WRT what? ********
#   if dist is near zero, then very similar (dark blue is same sample zero dist)
# use rlog-transformed data to avoid domination by a few highly variable genes
# dist calculates distances between rlog-transforms in data rows
#  our samples constitute columns so use t to transpose the matrix
distsRL <- dist(t(assay(rld)))
mat <- as.matrix(distsRL)
rownames(mat) <- colnames(mat) <- with(colData(dds), paste(condition,sampleName , sep=" : "))
# visualizes distances and clusters:
#From the Apr 2015 vignette
library("RColorBrewer")
library("gplots")
select <- order(rowMeans(counts(dds,normalized=TRUE)),decreasing=TRUE)[1:30]
hmcol <- colorRampPalette(brewer.pal(9, "GnBu"))(100)
hc <- hclust(distsRL)
heatmap.2(mat, Rowv=as.dendrogram(hc),
symm=TRUE, trace="none",
col = rev(hmcol), margin=c(13, 13))
if(readDepth=="2.5M")
{
dev.copy(png,"deseq2_heatmaps_samplebysample_2.5.png")
dev.off()
}
if(readDepth=="10M")
{
dev.copy(png,"deseq2_heatmaps_samplebysample_10.png")
dev.off()
}
else
{
dev.copy(png,"deseq2_heatmaps_samplebysample_30.png")
dev.off()
}
#PCA
colours <- c(rgb(1:3/4,0,0),rgb(0,1:3/4,0),rgb(0,0,1:3/4),rgb(1:3/4,0,1:3/4))
plotPCA( rld, intgroup = c("sampleName","condition") )
}
distsRL <- dist(t(assay(rld)))
plotPCA( rld, intgroup = c("sampleName","condition") )
